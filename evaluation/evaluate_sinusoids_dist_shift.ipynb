{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/EHAZAN/hd0216/informed-meta-learning/.cache/conda/envs/inps/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/scratch/gpfs/EHAZAN/hd0216/informed-meta-learning/.cache/conda/envs/inps/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import load_model\n",
    "from argparse import Namespace\n",
    "\n",
    "from dataset.dataset import SetKnowledgeTrendingSinusoidsDistShift\n",
    "from dataset.utils import get_dataloader\n",
    "from evaluation.utils import get_summary_df\n",
    "from models.loss import NLL\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"Dark2\")\n",
    "plt.rcParams[\"text.latex.preamble\"] = (\n",
    "    \"\\\\usepackage{lmodern} \\\\usepackage{times} \\\\usepackage{amssymb}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../saves/INPs_sinusoids/np_dist_shift_0\n",
      "../saves/INPs_sinusoids/inp_b_dist_shift_0\n"
     ]
    }
   ],
   "source": [
    "# Load the models\n",
    "save_dirs = {\n",
    "    \"NP\": \"../saves/INPs_sinusoids/np_dist_shift_0\",\n",
    "    \"INP\": \"../saves/INPs_sinusoids/inp_b_dist_shift_0\",\n",
    "}\n",
    "\n",
    "models = list(save_dirs.keys())\n",
    "model_dict = {}\n",
    "config_dict = {}\n",
    "\n",
    "for model_name, save_dir in save_dirs.items():\n",
    "    model_dict[model_name], config_dict[model_name] = load_model(\n",
    "        save_dir, load_it=\"best\"\n",
    "    )\n",
    "    model_dict[model_name].eval()\n",
    "\n",
    "model_names = list(model_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the dataloaders\n",
    "config = Namespace(\n",
    "    min_num_context=0,\n",
    "    max_num_context=100,\n",
    "    num_targets=100,\n",
    "    noise=0.2,\n",
    "    batch_size=25,\n",
    "    x_sampler=\"uniform\",\n",
    "    test_num_z_samples=32,\n",
    "    dataset=\"set-trending-sinusoids-dist-shift\",\n",
    "    device=\"cuda:0\",\n",
    ")\n",
    "\n",
    "test_dataset = SetKnowledgeTrendingSinusoidsDistShift(\n",
    "    root=\"../data/trending-sinusoids-dist-shift\", split=\"test\", knowledge_type=\"b\"\n",
    ")\n",
    "test_data_loader = get_dataloader(test_dataset, config)\n",
    "\n",
    "train_dataset = SetKnowledgeTrendingSinusoidsDistShift(\n",
    "    root=\"../data/trending-sinusoids-dist-shift\", split=\"train\", knowledge_type=\"b\"\n",
    ")\n",
    "train_data_loader = get_dataloader(train_dataset, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 44.56 MiB is free. Process 3808375 has 4.04 GiB memory in use. Process 4119427 has 588.00 MiB memory in use. Process 850094 has 7.39 GiB memory in use. Process 3328095 has 538.00 MiB memory in use. Process 1556005 has 576.00 MiB memory in use. Process 1566807 has 1.17 GiB memory in use. Process 2743205 has 458.00 MiB memory in use. Process 3120846 has 6.57 GiB memory in use. Process 3489735 has 418.00 MiB memory in use. Process 2647541 has 6.27 GiB memory in use. Process 3023310 has 5.94 GiB memory in use. Process 3192359 has 546.00 MiB memory in use. Process 3673783 has 1.84 GiB memory in use. Process 4073009 has 492.00 MiB memory in use. Process 4164489 has 1.12 GiB memory in use. Including non-PyTorch memory, this process has 1.52 GiB memory in use. Of the allocated memory 998.14 MiB is allocated by PyTorch, and 55.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m eval_type_ls = [\u001b[33m\"\u001b[39m\u001b[33mraw\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minformed\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m train_summary_df, _, train_output_dict = \u001b[43mget_summary_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_type_ls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_names\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m test_summary_df, _, test_output_dict = get_summary_df(\n\u001b[32m      7\u001b[39m     model_dict, config_dict, test_data_loader, eval_type_ls, model_names\n\u001b[32m      8\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/EHAZAN/hd0216/informed-meta-learning/evaluation/utils.py:178\u001b[39m, in \u001b[36mget_summary_df\u001b[39m\u001b[34m(model_dict, config_dict, data_loader, eval_type_ls, model_names, sampler)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m config.use_knowledge:\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m eval_type == \u001b[33m\"\u001b[39m\u001b[33minformed\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m         outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m            \u001b[49m\u001b[43mx_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m            \u001b[49m\u001b[43my_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m            \u001b[49m\u001b[43mx_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m            \u001b[49m\u001b[43my_target\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m            \u001b[49m\u001b[43mknowledge\u001b[49m\u001b[43m=\u001b[49m\u001b[43mknowledge\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    186\u001b[39m         mask = get_mask(eval_type)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/EHAZAN/hd0216/informed-meta-learning/.cache/conda/envs/inps/lib/python3.11/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/EHAZAN/hd0216/informed-meta-learning/.cache/conda/envs/inps/lib/python3.11/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/EHAZAN/hd0216/informed-meta-learning/models/inp.py:36\u001b[39m, in \u001b[36mINP.forward\u001b[39m\u001b[34m(self, x_context, y_context, x_target, y_target, knowledge)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# reshape z_samples to the shape of x_target\u001b[39;00m\n\u001b[32m     34\u001b[39m R_target = \u001b[38;5;28mself\u001b[39m.target_dependent_representation(R, x_target, z_samples)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m p_yCc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecode_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m p_yCc, z_samples, q_z_Cc, q_zCct\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/EHAZAN/hd0216/informed-meta-learning/models/inp.py:102\u001b[39m, in \u001b[36mINP.decode_target\u001b[39m\u001b[34m(self, x_target, R_target)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_target\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_target, R_target):\n\u001b[32m     99\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m    Decode the target set given the target dependent representation\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     p_y_stats = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m     p_y_loc, p_y_scale = p_y_stats.split(\u001b[38;5;28mself\u001b[39m.config.output_dim, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    106\u001b[39m     \u001b[38;5;66;03m# bound the variance (minimum 0.1)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/EHAZAN/hd0216/informed-meta-learning/.cache/conda/envs/inps/lib/python3.11/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/EHAZAN/hd0216/informed-meta-learning/.cache/conda/envs/inps/lib/python3.11/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/EHAZAN/hd0216/informed-meta-learning/models/modules.py:310\u001b[39m, in \u001b[36mDecoder.forward\u001b[39m\u001b[34m(self, x_target, R_target)\u001b[39m\n\u001b[32m    308\u001b[39m x_target = x_target.unsqueeze(\u001b[32m0\u001b[39m).expand(R_target.shape[\u001b[32m0\u001b[39m], -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m    309\u001b[39m XR_target = torch.cat([x_target, R_target], dim=-\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m p_y_stats = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXR_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m p_y_stats\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/EHAZAN/hd0216/informed-meta-learning/.cache/conda/envs/inps/lib/python3.11/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/EHAZAN/hd0216/informed-meta-learning/.cache/conda/envs/inps/lib/python3.11/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/EHAZAN/hd0216/informed-meta-learning/models/modules.py:24\u001b[39m, in \u001b[36mMLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[:-\u001b[32m1\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m         x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.layers[-\u001b[32m1\u001b[39m](x)\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/EHAZAN/hd0216/informed-meta-learning/.cache/conda/envs/inps/lib/python3.11/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/EHAZAN/hd0216/informed-meta-learning/.cache/conda/envs/inps/lib/python3.11/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/scratch/gpfs/EHAZAN/hd0216/informed-meta-learning/.cache/conda/envs/inps/lib/python3.11/site-packages/torch/nn/modules/activation.py:815\u001b[39m, in \u001b[36mGELU.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    811\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    812\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    813\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    814\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapproximate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapproximate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 44.56 MiB is free. Process 3808375 has 4.04 GiB memory in use. Process 4119427 has 588.00 MiB memory in use. Process 850094 has 7.39 GiB memory in use. Process 3328095 has 538.00 MiB memory in use. Process 1556005 has 576.00 MiB memory in use. Process 1566807 has 1.17 GiB memory in use. Process 2743205 has 458.00 MiB memory in use. Process 3120846 has 6.57 GiB memory in use. Process 3489735 has 418.00 MiB memory in use. Process 2647541 has 6.27 GiB memory in use. Process 3023310 has 5.94 GiB memory in use. Process 3192359 has 546.00 MiB memory in use. Process 3673783 has 1.84 GiB memory in use. Process 4073009 has 492.00 MiB memory in use. Process 4164489 has 1.12 GiB memory in use. Including non-PyTorch memory, this process has 1.52 GiB memory in use. Of the allocated memory 998.14 MiB is allocated by PyTorch, and 55.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "eval_type_ls = [\"raw\", \"informed\"]\n",
    "\n",
    "train_summary_df, _, train_output_dict = get_summary_df(\n",
    "    model_dict, config_dict, train_data_loader, eval_type_ls, model_names\n",
    ")\n",
    "test_summary_df, _, test_output_dict = get_summary_df(\n",
    "    model_dict, config_dict, test_data_loader, eval_type_ls, model_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summary_df[\"split\"] = \"train\"\n",
    "test_summary_df[\"split\"] = \"test\"\n",
    "\n",
    "plot_df = pd.concat([train_summary_df, test_summary_df])\n",
    "plot_df = plot_df[\n",
    "    ((plot_df.model_name == \"INP\") & (plot_df.eval_type == \"informed\"))\n",
    "    | ((plot_df.model_name == \"NP\") & (plot_df.eval_type == \"raw\"))\n",
    "]\n",
    "\n",
    "plot_df[\"mean\"] = -plot_df[\"mean\"]\n",
    "plot_df[\"eval_type\"] = plot_df[\"eval_type\"].map(\n",
    "    {\n",
    "        \"raw\": r\"NP: $\\mathcal{K} = \\varnothing$\",\n",
    "        \"informed\": r\"INP: $\\mathcal{K} \\neq \\varnothing$\",\n",
    "    }\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 3.5))\n",
    "sns.lineplot(\n",
    "    plot_df,\n",
    "    x=\"num_context\",\n",
    "    y=\"mean\",\n",
    "    hue=\"eval_type\",\n",
    "    style=\"split\",\n",
    "    palette=[\"C2\", \"C4\"],\n",
    "    markers=True,\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Negative Log-likelihood\")\n",
    "ax.set_xlabel(\"Number of context datapoints\")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "labels[0] = \"\"\n",
    "labels[3] = \"\"\n",
    "\n",
    "plt.legend(labels=labels, handles=handles)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('../figures/exp-2.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = NLL()\n",
    "\n",
    "\n",
    "def get_loss_bs(output_dict, model_name=\"INP\", eval_type=\"informed\", num_context=0):\n",
    "    bs_ls = []\n",
    "    this_loss_ls = []\n",
    "    for batch_idx in range(len(output_dict[model_name][eval_type][num_context])):\n",
    "        outputs = output_dict[model_name][eval_type][num_context][batch_idx][\"outputs\"]\n",
    "        y_target = output_dict[model_name][eval_type][num_context][batch_idx][\n",
    "            \"y_target\"\n",
    "        ]\n",
    "        knowledge = output_dict[model_name][eval_type][num_context][batch_idx][\n",
    "            \"knowledge\"\n",
    "        ].cpu()\n",
    "        bs = knowledge[:, 0, 3]\n",
    "\n",
    "        this_loss, _, _ = loss.get_loss(\n",
    "            outputs[0], outputs[1].cuda(), outputs[2], outputs[3], y_target.cuda()\n",
    "        )\n",
    "        this_loss = this_loss.cpu()\n",
    "        this_loss_ls.append(this_loss)\n",
    "        bs_ls.append(bs)\n",
    "\n",
    "    bs = torch.cat(bs_ls)\n",
    "    this_loss = torch.cat(this_loss_ls)\n",
    "\n",
    "    return this_loss, bs\n",
    "\n",
    "\n",
    "train_loss_informed, train_bs_informed = get_loss_bs(\n",
    "    train_output_dict, eval_type=\"informed\"\n",
    ")\n",
    "test_loss_informed, test_bs_informed = get_loss_bs(\n",
    "    test_output_dict, eval_type=\"informed\"\n",
    ")\n",
    "test_loss_raw, test_bs_raw = get_loss_bs(\n",
    "    test_output_dict, eval_type=\"raw\", model_name=\"NP\"\n",
    ")\n",
    "\n",
    "\n",
    "bins = np.linspace(-0.5, 6, 10)\n",
    "\n",
    "raw_df = pd.DataFrame({\"b\": test_bs_raw, \"loss\": torch.log(test_loss_raw)})\n",
    "raw_df[\"bin\"] = pd.cut(raw_df[\"b\"], bins=bins)\n",
    "raw_df[\"eval_type\"] = \"raw\"\n",
    "informed_df = pd.DataFrame(\n",
    "    {\"b\": test_bs_informed, \"loss\": torch.log(test_loss_informed)}\n",
    ")\n",
    "informed_df[\"bin\"] = pd.cut(raw_df[\"b\"], bins=bins)\n",
    "informed_df[\"eval_type\"] = \"informed\"\n",
    "all_df = pd.concat([raw_df, informed_df]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(3, 3.5), sharex=True, height_ratios=[2, 1])\n",
    "\n",
    "sns.regplot(\n",
    "    data=raw_df,\n",
    "    label=r\"NP: $\\mathcal{K} = \\varnothing$\",\n",
    "    ax=axs[0],\n",
    "    x_ci=\"sd\",\n",
    "    x=\"b\",\n",
    "    y=\"loss\",\n",
    "    x_bins=bins,\n",
    "    fit_reg=False,\n",
    "    color=\"C2\",\n",
    ")\n",
    "sns.regplot(\n",
    "    data=informed_df,\n",
    "    label=r\"INP: $\\mathcal{K} \\neq \\varnothing$\",\n",
    "    ax=axs[0],\n",
    "    x_ci=\"sd\",\n",
    "    x=\"b\",\n",
    "    y=\"loss\",\n",
    "    x_bins=bins,\n",
    "    fit_reg=False,\n",
    "    color=\"C4\",\n",
    ")\n",
    "\n",
    "\n",
    "axs[1].hist(\n",
    "    train_bs_informed, color=\"grey\", alpha=0.8, bins=bins, density=True, align=\"left\"\n",
    ")\n",
    "axs[0].legend()\n",
    "axs[0].legend(\n",
    "    handletextpad=0.05,\n",
    "    loc=\"lower right\",\n",
    "    facecolor=\"white\",\n",
    "    framealpha=0.8,\n",
    "    frameon=True,\n",
    ")\n",
    "axs[0].set_ylabel(\"test log(loss)\")\n",
    "axs[1].set_ylabel(\"\\% of training tasks\")\n",
    "axs[0].set_xlabel(\"\")\n",
    "axs[1].set_xlabel(\"Value of $b$\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig('../figures/ood_details.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
